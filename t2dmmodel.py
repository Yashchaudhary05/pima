# -*- coding: utf-8 -*-
"""T2DMmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b-orCRWzm3jr4QAiuf8LZfUub2sN3v4u
"""

#importing libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from warnings import filterwarnings
filterwarnings(action='ignore')
acc=[]

"""# ***Loading Dataset***

"""

url = 'https://raw.githubusercontent.com/Yashchaudhary05/pima/main/aims_diabetes_data.csv'
data = pd.read_csv(url)
print()
print("< < < < < < < < < < < < < < <  Data Imported Succesfully > > > > > > > > > > > > > > > ")
print()
data.head()

"""### ***Data Description***"""

print(data.shape)
print()
print()

"""### ***Finding Null Values***"""

print(data.isna().sum())

"""### ***Correlation***"""

data.corr()

"""### **Age-Mean Grouping**"""

data.groupby('Age').mean()

"""### ***Data Analysis***

## ***Distplot:***
"""

sns.distplot(data['Outcome'])

sns.distplot(data['BMI'])

sns.distplot(data['Pregnancies'])

sns.distplot(data['Age'])

sns.distplot(data['BloodPressure'])

sns.distplot(data['SkinThickness'])

"""## ***BoxPlot***"""

data.plot(kind ='box',subplots = True, layout =(3,3),sharex = False,figsize=(15, 10))

"""## ***Density Plot***"""

data.plot(kind ='density',subplots = True, layout =(3,3),sharex = False,figsize=(15, 10))

"""## ***Histogram***"""

data.hist(figsize=(15,10),bins=50)
plt.show()

"""## ***Heatmap***"""

plt.figure(figsize=(15, 10))
corr = data.corr()
sns.heatmap(corr, annot=True)
plt.show()

"""## ***Outlier Visualization***"""

sns.set(style="whitegrid")
data.boxplot(figsize=(15,10))

"""## ***Pairplot***"""

sns.pairplot(data,hue='Outcome')

"""### ***Feature Selection***"""

X = data.drop(columns=['Outcome'])
Y = data['Outcome']
print("< < < < < < < < < < < < < < < Feature Extraction Sucessfull!! > > > > > > > > > > > > > > >")

"""## ***PREPROCESSING***"""

from sklearn.ensemble import ExtraTreesClassifier
classifiern = ExtraTreesClassifier()
classifiern.fit(X,Y)
score = classifiern.feature_importances_
print(score)

"""## ***DATA_SPLITTING***"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)
modelname=[]

"""## ***LINEAR_REGRESSION***"""

print("< < < < < < < < < < < < < < < LogisticRegression > > > > > > > > > > > > > > >")
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train,Y_train)
Y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score,confusion_matrix
print("Accuracy Score:",accuracy_score(Y_test,Y_pred))
acc.append(accuracy_score(Y_test,Y_pred))
modelname.append("LR")

confusion_mat = confusion_matrix(Y_test,Y_pred)
print("confusion matrix:",confusion_mat)

"""## ***KNN***"""

print("< < < < < < < < < < < < < < < KNeighborsClassifier > > > > > > > > > > > > > > >")
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
acc.append(accuracy_score(Y_test,y_pred))
modelname.append("KNN")

confusion_mat = confusion_matrix(Y_test,y_pred)
print("confusion matrix:",confusion_mat)

"""## ***Support_Vector_Classifier***"""

print("< < < < < < < < < < < < < < < Support_Vector_Classifier > > > > > > > > > > > > > > >")
from sklearn.svm import SVC
model = SVC()
model.fit(X_train,Y_train)
pred_y = model.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,pred_y))
acc.append(accuracy_score(Y_test,pred_y))
modelname.append("SVC")

confusion_mat = confusion_matrix(Y_test,pred_y)
print("confusion matrix:",confusion_mat)

"""## ***Decison_Tree_Classifier***"""

print("< < < < < < < < < < < < < < < Decison_Tree_Classifier > > > > > > > > > > > > > > >")
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier(criterion='entropy',random_state=7)
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
acc.append(accuracy_score(Y_test,y_pred))
modelname.append("DTC")

confusion_mat = confusion_matrix(Y_test,y_pred)
print("confusion matrix:",confusion_mat)

"""## ***Gaussian_Naive_Bayes***"""

print("< < < < < < < < < < < < < < < Gaussian_Naive_Bayes > > > > > > > > > > > > > > >")
from sklearn.naive_bayes import GaussianNB
model3 = GaussianNB()
model3.fit(X_train,Y_train)
y_pred3 = model3.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred3))
acc.append(accuracy_score(Y_test,y_pred3))
modelname.append("GNBC")

confusion_mat = confusion_matrix(Y_test,y_pred3)
print("confusion matrix:",confusion_mat)

"""## ***Random_forest***"""

print("< < < < < < < < < < < < < < < Random_forest > > > > > > > > > > > > > > >")
from sklearn.ensemble import RandomForestClassifier
model2 = RandomForestClassifier(random_state=1)
model2.fit(X_train, Y_train)
y_pred2 = model2.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred2))
acc.append(accuracy_score(Y_test,y_pred2))
modelname.append("RF")

confusion_mat = confusion_matrix(Y_test,y_pred2)
print("confusion matrix:",confusion_mat)

"""## ***XGBoost***"""

print("< < < < < < < < < < < < < < < XGBoost > > > > > > > > > > > > > > >")
import xgboost as xgb
model5 = xgb.XGBClassifier(random_state=1)
model5.fit(X_train, Y_train)
y_pred5 = model5.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred5))
acc.append(accuracy_score(Y_test,y_pred5))
modelname.append("XGB")

confusion_mat = confusion_matrix(Y_test,y_pred5)
print("confusion matrix:",confusion_mat)

"""## ***Results***"""

results = dict(zip(modelname,acc))
for key, value in results.items():
    print(f'{key}: {value}')

"""## *#hence, we will be using DTC and RandomForest for our model based on accuracy....*

# Model for diabetes prediction :
### i) Decision tree Classifier
### ii) Random  Forest
"""

from sklearn.preprocessing import StandardScaler
url = 'https://raw.githubusercontent.com/Yashchaudhary05/pima/main/aims_diabetes_data.csv'
df = pd.read_csv(url)
print("< < < < < < < < < < < < < < < data read successful > > > > > > > > > > > > > > > ")
df.head()
# Preprocess the data
X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Train different models
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier()
}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{name} accuracy: {accuracy:.2f}')

# Create a user interface to input data and get predictions
def predict_diabetes(Data):
    # Convert input data to a numpy array
    data_array = np.asarray(Data)

    # Standardize the data
    data_scaled = scaler.transform(data_array.reshape(1, -1))

    # Make predictions using different models
    predictions = {}
    for name, model in models.items():
        predictions[name] = model.predict(data_scaled)[0]

    return predictions

print()
print()
print()
print()

# Get user input
Data = []
for feature in X.columns:
    value = float(input(f'Enter {feature}: '))
    Data.append(value)

# Get predictions
predictions = predict_diabetes(Data)
print(predictions)

# Display results
for name, prediction in predictions.items():
    if prediction == 0:
        print(f'{name}: You are fit and fine , goodluck mainting this achievement....')
    else:
        print(f'{name}: Diabetes Detected ')


print()
print()